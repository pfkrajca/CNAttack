{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fc8Z4NJ6YRPC"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.sparse import issparse\n","\n","def plot_cluster_means_by_genomic_position(adata, layer=\"counts\", group_by=\"cell_type\", downsample=100):\n","    \"\"\"\n","    Plots mean expression across genomic positions for each group in `adata`.\n","\n","    Parameters:\n","    - adata: AnnData object with `layers[layer]` and `obs[group_by]` defined.\n","    - layer: Layer name containing count data.\n","    - group_by: Column in `adata.obs` to group cells (e.g., \"cell_type\").\n","    - downsample: Plot every nth gene to reduce visual clutter.\n","    \"\"\"\n","    gene_indices = np.arange(0, adata.n_vars, downsample)\n","\n","    # Get chromosome info if available\n","    chromosomes = adata.var[\"chromosome\"].values[gene_indices] if \"chromosome\" in adata.var else None\n","\n","    if chromosomes is not None:\n","        valid_chroms = [str(i) for i in range(1, 23)] + ['X', 'chrX']\n","        chrom_mask = np.isin(chromosomes, valid_chroms)\n","        chrom_changes = np.where((chromosomes[:-1] != chromosomes[1:]) &\n","                                 (chrom_mask[:-1] | chrom_mask[1:]))[0] + 1\n","        chrom_boundaries = [0] + chrom_changes.tolist() + [len(chromosomes)]\n","        chrom_midpoints = [(chrom_boundaries[i] + chrom_boundaries[i+1]) // 2\n","                           for i in range(len(chrom_boundaries)-1)]\n","        chrom_labels = [chromosomes[i] for i in chrom_boundaries[:-1]]\n","\n","    # Calculate global Y-axis limits\n","    all_means = []\n","    for group in adata.obs[group_by].unique():\n","        group_mask = adata.obs[group_by] == group\n","        group_data = adata[group_mask].layers[layer][:, gene_indices]\n","        if issparse(group_data):\n","            group_data = group_data.toarray()\n","        all_means.append(np.mean(group_data, axis=0))\n","\n","    global_ymin = min(np.min(means) for means in all_means)\n","    global_ymax = max(np.max(means) for means in all_means)\n","    y_padding = (global_ymax - global_ymin) * 0.1\n","\n","    # 1. Combined Plot\n","    plt.figure(figsize=(14, 6))\n","    for group, means in zip(adata.obs[group_by].unique(), all_means):\n","        plt.plot(means, label=f\"{group}\", linewidth=1)\n","\n","    if chromosomes is not None:\n","        for x in chrom_boundaries[1:-1]:\n","            if chrom_mask[x]:\n","                plt.axvline(x, color='gray', linestyle='--', alpha=0.5, linewidth=0.5)\n","        plt.xticks(\n","            [mp for mp, lbl in zip(chrom_midpoints, chrom_labels) if lbl in valid_chroms],\n","            [lbl for lbl in chrom_labels if lbl in valid_chroms],\n","            rotation=90\n","        )\n","\n","    plt.ylim(global_ymin - y_padding, global_ymax + y_padding)\n","    plt.title(f\"All Groups (Downsampled {downsample}x)\")\n","    plt.xlabel(\"Genomic Position\")\n","    plt.ylabel(\"Mean Counts\")\n","    plt.legend(bbox_to_anchor=(1.05, 1))\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # 2. Individual Group Plots\n","    for group, means in zip(adata.obs[group_by].unique(), all_means):\n","        plt.figure(figsize=(14, 4))\n","        plt.plot(means, color='steelblue', linewidth=1)\n","\n","        if chromosomes is not None:\n","            for x in chrom_boundaries[1:-1]:\n","                if chrom_mask[x]:\n","                    plt.axvline(x, color='gray', linestyle='--', alpha=0.5, linewidth=0.5)\n","            plt.xticks(\n","                [mp for mp, lbl in zip(chrom_midpoints, chrom_labels) if lbl in valid_chroms],\n","                [lbl for lbl in chrom_labels if lbl in valid_chroms],\n","                rotation=90\n","            )\n","\n","        plt.ylim(global_ymin - y_padding, global_ymax + y_padding)\n","        plt.title(f\"Group: {group}\\n(Mean Expression, {downsample}x downsampled)\")\n","        plt.xlabel(\"Genomic Position\")\n","        plt.ylabel(\"Mean Counts\")\n","        plt.tight_layout()\n","        plt.show()"]},{"cell_type":"code","source":["def order_genes_by_position(adata: AnnData) -> AnnData:\n","    \"\"\"\n","    Orders the variables (genes) in the AnnData object by chromosome and start.\n","    \"\"\"\n","    gene_order = (\n","        adata.var\n","        .sort_values(['chromosome', 'start'])\n","        .index\n","    )\n","    return adata[:, gene_order]\n","\n","\n","def smooth_expression_matrix(matrix: pd.DataFrame, window_size: int = 25) -> pd.DataFrame:\n","    \"\"\"\n","    Applies a sliding window average across genes.\n","    \"\"\"\n","    smoothed = []\n","    gene_names = matrix.columns.to_list()\n","\n","    for i in range(len(gene_names) - window_size + 1):\n","        window = gene_names[i:i + window_size]\n","        avg_expr = matrix[window].mean(axis=1)\n","        smoothed.append(avg_expr.rename(f\"{window[0]}_to_{window[-1]}\"))\n","\n","    return pd.concat(smoothed, axis=1)\n","\n","\n","\n","def compute_smoothed_profiles_from_adata(\n","    adata: AnnData,\n","    use_layer: str = None,\n","    group_by: str = 'cell_type',\n","    window_size: int = 25,\n","    ref: str = 'Monocyte'\n",") -> Tuple[pd.DataFrame, Dict[str, pd.Series], pd.Series, pd.Series]:\n","    \"\"\"\n","    Computes smoothed expression profiles from an AnnData object.\n","    Returns:\n","    - Per-cell smoothed expression DataFrame\n","    - Dictionary of per-cell-type smoothed average Series\n","    - Global average Series\n","    - Reference cluster average Series\n","    \"\"\"\n","    # Step 1: Order genes\n","    adata_ordered = order_genes_by_position(adata)\n","\n","    # Step 2: Get expression matrix\n","    if use_layer:\n","        expr = pd.DataFrame(\n","            adata_ordered.layers[use_layer].toarray(),\n","            index=adata_ordered.obs_names,\n","            columns=adata_ordered.var_names\n","        )\n","    else:\n","        expr = pd.DataFrame(\n","            adata_ordered.X.toarray() if hasattr(adata_ordered.X, \"toarray\") else adata_ordered.X,\n","            index=adata_ordered.obs_names,\n","            columns=adata_ordered.var_names\n","        )\n","\n","    # Step 3: Smooth once for all cells\n","    smoothed_expr = smooth_expression_matrix(expr, window_size)\n","\n","    # Step 4: Global average\n","    global_avg = smoothed_expr.mean(axis=0)\n","\n","    # Step 5: Per-cell-type averages (vectorized)\n","    celltypes = adata_ordered.obs[group_by]\n","    celltype_profiles = {\n","        ct: smoothed_expr.loc[celltypes == ct].mean(axis=0)\n","        for ct in celltypes.unique()\n","    }\n","\n","    # Step 6: Reference cluster average\n","    if ref in celltype_profiles:\n","        ref_avg = celltype_profiles[ref]\n","    else:\n","        raise ValueError(f\"Reference cell type '{ref}' not found in adata.obs['{group_by}'].\")\n","\n","    return smoothed_expr, celltype_profiles, global_avg, ref_avg\n"],"metadata":{"id":"27OEdmASYXud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_all_cell_zscores_to_adata_optimized(smoothed: pd.DataFrame,\n","                                                celltype_avg: dict,\n","                                                global_avg: pd.Series,\n","                                                cluster_avg: pd.Series,\n","                                                adata: AnnData,\n","                                                group_by: str = 'cell_type') -> AnnData:\n","    \"\"\"\n","    Optimized memory-efficient version to compute z-score deltas and store them in `adata.obsm`.\n","\n","    will store as adata.obsm['delta_global_z'], adata.obsm['delta_celltype_z'], adata.obsm['delta_cluster_z']\n","    \"\"\"\n","\n","    cells = smoothed.index\n","    genes = smoothed.columns\n","    n_cells, n_genes = smoothed.shape\n","\n","    # Precompute arrays for faster access\n","    smoothed_np = smoothed.values\n","    global_avg_np = global_avg.values\n","    cluster_avg_np = cluster_avg.values\n","\n","    # Build a matrix of per-cell-type averages aligned to cells\n","    group = adata.obs.loc[cells, group_by].values\n","    celltype_avg_np = np.stack([celltype_avg[ct].loc[genes].values for ct in group])\n","\n","    # Allocate arrays\n","    delta_global_z = np.zeros_like(smoothed_np)\n","    delta_celltype_z = np.zeros_like(smoothed_np)\n","    delta_cluster_z = np.zeros_like(smoothed_np)\n","\n","    # Helper function: z-score along gene axis (per cell)\n","    def zscore_rowwise(matrix):\n","        mean = matrix.mean(axis=1, keepdims=True)\n","        std = matrix.std(axis=1, keepdims=True)\n","        std[std == 0] = 1  # prevent division by zero\n","        return (matrix - mean) / std\n","\n","    # Compute deltas\n","    delta_global = smoothed_np - global_avg_np\n","    delta_celltype = smoothed_np - celltype_avg_np\n","    delta_cluster = smoothed_np - cluster_avg_np\n","\n","    # Z-score normalize each row (cell)\n","    delta_global_z = zscore_rowwise(delta_global)\n","    delta_celltype_z = zscore_rowwise(delta_celltype)\n","    delta_cluster_z = zscore_rowwise(delta_cluster)\n","\n","    # Store results in adata.obsm\n","    adata.obsm['delta_global_z'] = delta_global_z\n","    adata.obsm['delta_celltype_z'] = delta_celltype_z\n","    adata.obsm['delta_cluster_z'] = delta_cluster_z\n","    adata.uns['delta_zscore_genes'] = list(genes)\n","\n","    return adata\n"],"metadata":{"id":"3e8PPI64YbFN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def filter_and_count_zscores(\n","    zscore_array,\n","    upper_thresh: float = 1.0,\n","    lower_thresh: float = -1.0,\n","    min_cells: int = 600,\n","    adata: AnnData = None,\n","    obsm_key: str = None\n",") -> Tuple[pd.DataFrame, pd.Series, pd.Series]:\n","    \"\"\"\n","    Robust z-score filtering with proper AnnData alignment\n","\n","    Parameters:\n","        zscore_array: Input array (cells × genes)\n","        upper_thresh/lower_thresh: Significance thresholds\n","        min_cells: Minimum cells with significant changes\n","        adata: AnnData object (must match zscore_array rows)\n","        obsm_key: Key for storing filtered matrix in adata.obsm\n","\n","    Returns:\n","        Tuple of (filtered_df, up_counts, down_counts)\n","    \"\"\"\n","\n","    # Validate dimensions\n","    if adata is not None:\n","        if zscore_array.shape[0] != adata.n_obs:\n","            raise ValueError(f\"zscore_array has {zscore_array.shape[0]} cells, adata has {adata.n_obs}\")\n","\n","    # Convert to DataFrame with proper gene names\n","    zscore_df = pd.DataFrame(\n","        zscore_array,\n","        index=adata.obs_names if adata else None,\n","        columns=adata.var_names[:zscore_array.shape[1]] if adata else None\n","    )\n","\n","    # Create significance masks\n","    sig_mask = (zscore_df > upper_thresh) | (zscore_df < lower_thresh)\n","    sig_counts = sig_mask.sum(axis=0)  # Count per gene\n","\n","    # Filter genes\n","    keep_genes = sig_counts >= min_cells\n","    filtered_df = zscore_df.where(sig_mask & keep_genes, None)\n","\n","    # Store in AnnData if requested\n","    if adata is not None and obsm_key is not None:\n","        # Create full-sized matrix aligned with adata.var\n","        filtered_matrix = np.zeros((adata.n_obs, adata.n_vars))\n","        filtered_matrix[:, :zscore_array.shape[1]] = filtered_df.values\n","        adata.obsm[obsm_key] = filtered_matrix\n","\n","        # Store which genes were kept\n","        adata.uns[f\"{obsm_key}_genes\"] = filtered_df.columns.tolist()\n","\n","    # Count significant events\n","    up_counts = (zscore_df > upper_thresh).sum(axis=0)\n","    down_counts = (zscore_df < lower_thresh).sum(axis=0)\n","\n","    print(f\"Filtered to {keep_genes.sum()} genes with changes in ≥{min_cells} cells\")\n","    return filtered_df.loc[:, keep_genes], up_counts, down_counts"],"metadata":{"id":"Lg1mju_gYsPK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def detect_cnvs_with_hmm_final(adata, matrix_name=\"filtered_z\", n_components=3,\n","                             n_iter=50, random_state=42, output_prefix=\"hmm_cnv\",\n","                             min_non_nan=20, chunk_size=100):\n","    \"\"\"\n","    Final robust HMM implementation that:\n","    1. Uses pre-initialized model parameters\n","    2. Handles sparse data gracefully\n","    3. Provides detailed error reporting\n","    4. Stores per-gene HMM state and posterior in adata.var\n","    \"\"\"\n","\n","    if matrix_name not in adata.obsm:\n","        raise ValueError(f\"Matrix '{matrix_name}' not found in adata.obsm\")\n","\n","    data = adata.obsm[matrix_name]\n","    n_cells, n_features = data.shape\n","\n","    all_states = np.full(n_features, -1, dtype=np.int8)\n","    all_posteriors = np.full((n_features, n_components), np.nan, dtype=np.float16)\n","\n","    print(\"Identifying valid features...\")\n","    valid_features = [f for f in range(n_features) if np.sum(~np.isnan(data[:, f])) >= min_non_nan]\n","\n","    if len(valid_features) < n_components:\n","        raise ValueError(f\"Only {len(valid_features)} valid features found - need at least {n_components} for HMM\")\n","\n","    # Initialize HMM model\n","    model = hmm.GaussianHMM(\n","        n_components=n_components,\n","        covariance_type=\"diag\",\n","        n_iter=0,\n","        init_params=\"\",\n","        means_prior=np.linspace(-2, 2, n_components).reshape(-1, 1),\n","        covars_prior=np.ones((n_components, 1)),\n","        transmat_prior=np.full((n_components, n_components), 1/n_components),\n","        random_state=random_state\n","    )\n","\n","    model_fitted = False\n","\n","    print(\"Processing in chunks...\")\n","    for chunk_start in tqdm(range(0, len(valid_features), chunk_size)):\n","        chunk_features = valid_features[chunk_start:chunk_start + chunk_size]\n","        chunk = data[:, chunk_features]\n","\n","        valid_cells = ~np.isnan(chunk).any(axis=1)\n","        clean_chunk = chunk[valid_cells, :]\n","\n","        if clean_chunk.shape[0] < min_non_nan:\n","            continue\n","\n","        with warnings.catch_warnings():\n","            warnings.simplefilter(\"ignore\")\n","            scaled_chunk = StandardScaler().fit_transform(clean_chunk)\n","\n","        if not model_fitted:\n","            try:\n","                model.n_iter = n_iter\n","                model.fit(scaled_chunk.T)\n","                model_fitted = True\n","                print(\"Model successfully fitted!\")\n","            except Exception as e:\n","                print(f\"Fit failed: {str(e)}\")\n","                continue\n","\n","        try:\n","            states = model.predict(scaled_chunk.T)\n","            posteriors = model.predict_proba(scaled_chunk.T)\n","\n","            for i, f in enumerate(chunk_features):\n","                all_states[f] = states[i]\n","                all_posteriors[f] = posteriors[i].astype(np.float16)\n","        except Exception as e:\n","            print(f\"Prediction failed for chunk {chunk_start}: {str(e)}\")\n","            continue\n","\n","    if not model_fitted:\n","        raise RuntimeError(\"Could not fit HMM to any data chunks\")\n","\n","    # Store in adata.var\n","    adata.var[f\"{output_prefix}_state\"] = -1\n","    for i in range(n_components):\n","        adata.var[f\"{output_prefix}_prob_state_{i}\"] = np.nan\n","\n","    for idx, gene in enumerate(adata.var_names):\n","        adata.var.loc[gene, f\"{output_prefix}_state\"] = int(all_states[idx])\n","        for i in range(n_components):\n","            adata.var.loc[gene, f\"{output_prefix}_prob_state_{i}\"] = all_posteriors[idx, i]\n","\n","    print(\"Stored HMM states and posteriors in adata.var\")\n","    return adata\n"],"metadata":{"id":"5-VZVBqcYvEp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_detected_cnvs_with_cell_counts(\n","    adata,\n","    state_col='hmm_cnv_state',\n","    output_col='detected_cnvs',\n","    chrom_col='chromosome',\n","    start_col='start',\n","    end_col='end',\n","    group_by_col='cell_type',\n","    max_gap=1e6,\n","    min_region_size=1000,\n","    z_threshold=1.5\n","):\n","    \"\"\"\n","    Formats detected CNVs:\n","    - Excludes neutral regions\n","    - Merges overlapping CNVs\n","    - Counts affected cells per region and cell type\n","    - Annotates CNV type (gain/loss)\n","    \"\"\"\n","\n","    import pandas as pd\n","    import numpy as np\n","    from scipy.stats import zscore\n","    import warnings\n","\n","    # Only consider CNV states (not neutral)\n","    valid_states = [0, 2]\n","    valid_features = adata.var[state_col].isin(valid_states)\n","    sorted_vars = adata.var[valid_features].sort_values([chrom_col, start_col])\n","\n","    if len(sorted_vars) == 0:\n","        print(\"No CNV regions found!\")\n","        adata.obs[output_col] = \"neutral\"\n","        return adata, pd.DataFrame()\n","\n","    # Map state to CN type\n","    state_to_cn = {\n","        0: '0',   # Deletion\n","        2: '4'    # Amplification\n","    }\n","    cn_to_type = {\n","        '0': 'loss',\n","        '4': 'gain'\n","    }\n","\n","    # Build regions list\n","    regions = []\n","    for _, row in sorted_vars.iterrows():\n","        cn = state_to_cn[row[state_col]]\n","        regions.append({\n","            'chrom': row[chrom_col],\n","            'start': float(row[start_col]),\n","            'end': float(row[end_col]),\n","            'cn': cn,\n","            'cnv_type': cn_to_type[cn],\n","            'genes': [row.name]\n","        })\n","\n","    # Merge overlapping CNVs\n","    merged = []\n","    current = None\n","\n","    for region in sorted(regions, key=lambda x: (x['chrom'], x['start'])):\n","        if current is None:\n","            current = region.copy()\n","            continue\n","\n","        if (\n","            region['chrom'] == current['chrom']\n","            and region['cn'] == current['cn']\n","            and region['start'] <= current['end'] + max_gap\n","        ):\n","            current['end'] = max(current['end'], region['end'])\n","            current['genes'].extend(region['genes'])\n","        else:\n","            if current['end'] - current['start'] >= min_region_size:\n","                merged.append(current)\n","            current = region.copy()\n","\n","    if current and current['end'] - current['start'] >= min_region_size:\n","        merged.append(current)\n","\n","    if not merged:\n","        print(\"No valid CNV regions after merging.\")\n","        adata.obs[output_col] = \"neutral\"\n","        return adata, pd.DataFrame()\n","\n","    # Create CNV matrix and collect stats\n","    results = []\n","    cell_cnv_matrix = np.zeros((adata.n_obs, len(merged)), dtype=bool)\n","\n","    for i, region in enumerate(merged):\n","        expr = adata[:, region['genes']].X\n","        if hasattr(expr, 'toarray'):\n","            expr = expr.toarray()\n","\n","        with warnings.catch_warnings():\n","            warnings.simplefilter(\"ignore\")\n","            z_scores = zscore(expr, axis=0, nan_policy='omit')\n","            region_z = np.nanmean(z_scores, axis=1)\n","\n","        # Determine affected cells\n","        if region['cn'] == '0':\n","            cnv_cells = region_z < -z_threshold\n","        elif region['cn'] == '4':\n","            cnv_cells = region_z > z_threshold\n","        else:\n","            cnv_cells = np.zeros(adata.n_obs, dtype=bool)\n","\n","        cell_cnv_matrix[:, i] = cnv_cells\n","        n_cells = np.sum(cnv_cells)\n","\n","        # Count by cell type\n","        if group_by_col in adata.obs.columns:\n","            cell_types = adata.obs.loc[cnv_cells, group_by_col]\n","            cell_type_counts = cell_types.value_counts().to_dict()\n","        else:\n","            cell_type_counts = {}\n","\n","        region_str = f\"{region['chrom']}:{int(region['start'])}-{int(region['end'])} (CN {region['cn']})\"\n","\n","        results.append({\n","            'region': region_str,\n","            'n_cells': n_cells,\n","            'genes': ','.join(region['genes']),\n","            'cnv_type': region['cnv_type'],\n","            'group_by_counts': cell_type_counts\n","        })\n","\n","    # Final DataFrame\n","    cnv_df = pd.DataFrame(results).sort_values('n_cells', ascending=False)\n","    cnv_df['percent_cells'] = (cnv_df['n_cells'] / adata.n_obs * 100).round(1)\n","\n","    # Assign CNVs to cells\n","    adata.obs[output_col] = \"neutral\"\n","    for i in range(len(merged)):\n","        region_str = cnv_df.iloc[i]['region']\n","        adata.obs.loc[cell_cnv_matrix[:, i], output_col] = region_str\n","\n","    # Handle multiple CNVs per cell\n","    multi_cnv_cells = np.sum(cell_cnv_matrix, axis=1) > 1\n","    if np.any(multi_cnv_cells):\n","        for cell_idx in np.where(multi_cnv_cells)[0]:\n","            patterns = [\n","                cnv_df.iloc[i]['region']\n","                for i in np.where(cell_cnv_matrix[cell_idx])[0]\n","            ]\n","            adata.obs.iloc[cell_idx, adata.obs.columns.get_loc(output_col)] = \"; \".join(patterns)\n","\n","    print(f\"Detected {len(merged)} CNV regions across {np.sum(cell_cnv_matrix)} cell-region pairs\")\n","    print(\"\\nTop CNV regions by cell count:\")\n","    print(cnv_df.head())\n","\n","    # Store extra info\n","    adata.uns['cnv_stats'] = {\n","        'total_regions': len(merged),\n","        'total_cell_cnv_pairs': np.sum(cell_cnv_matrix),\n","        'cells_with_cnvs': np.sum(adata.obs[output_col] != \"neutral\"),\n","        'cell_cnv_matrix': cell_cnv_matrix,\n","        'merged_regions': merged\n","    }\n","\n","    return adata, cnv_df\n"],"metadata":{"id":"NA8poXleYzAE"},"execution_count":null,"outputs":[]}]}